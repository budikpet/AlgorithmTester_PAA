{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of output files\n",
    "## Prepare environment, functions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas\n",
    "import matplotlib\n",
    "import numpy\n",
    "from algorithm_tester.helpers import FilePair\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Zapnout zobrazování grafů (procento uvozuje „magickou” zkratku IPythonu):\n",
    "%matplotlib inline\n",
    "\n",
    "path = 'tester_results'\n",
    "evo_path = f'tester_results_evo'\n",
    "sol_path = '../data'\n",
    "\n",
    "sol_cols = [\"output_filename\", \"best_value\"]\n",
    "evo_cols = [\"output_filename\", \"num_of_satisfied_clauses\", \"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas.set_option('display.max_rows', None)\n",
    "#pandas.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths_from_dir(path: str, include_sol: bool = False, include_instance: bool = True) -> (str, str, str):\n",
    "    dataset_prefix: str = path.split(\"/\")[-1]\n",
    "    for root, _, files in os.walk(path):\n",
    "        dataset: str = dataset_prefix + \"_\" + \"_\".join(root.replace(path, \"\")[1:].split('/'))\n",
    "        for file in files:\n",
    "            if \"column\" not in file and \".dat\" in file:\n",
    "                if (\"_sol\" in file and include_sol) or (\"_inst\" in file and include_instance):\n",
    "                    yield (dataset, root, file)\n",
    "\n",
    "def get_cols_list(path: str):\n",
    "    cols = pandas.read_csv(path, index_col=None, delimiter=\" \", header=None)\n",
    "    return list(cols.iloc[0])\n",
    "\n",
    "def save_table(table, output_name):\n",
    "    table.round(6).to_excel(f\"excel/{output_name}_table.xlsx\", sheet_name=output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(table, title: str, column_name: str, output_name: str, y_label: str = \"Relative errors\"):\n",
    "    worktable = table.loc[:, column_name].copy()\n",
    "    \n",
    "    plot = worktable.plot.bar()\n",
    "    plot.set_ylabel(y_label)\n",
    "\n",
    "    figure = plot.get_figure()\n",
    "    figure.suptitle(title)\n",
    "    figure.savefig(f\"excel/{output_name}.pdf\", bbox_inches='tight')\n",
    "    \n",
    "    return plot\n",
    "\n",
    "def init_evo_plot(title: str, ylabel: str = \"Satisfied clauses\", figsize = [13,3]):\n",
    "    fig, axes = plt.subplots(1, 1, sharex=True, sharey=True, figsize=figsize)\n",
    "    axes.set_xlabel('step')\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_title(title)\n",
    "    \n",
    "    return fig, axes\n",
    "\n",
    "def get_evo_table(path: str, column: str = \"num_of_satisfied_clauses\"):\n",
    "    evo_table = pandas.read_csv(path, index_col=None, delimiter=\" \", header=None)\n",
    "    evo_table.columns = evo_cols\n",
    "    evo_table[\"step\"] = range(evo_table[column].count())\n",
    "    return evo_table\n",
    "\n",
    "def add_optimal_sol_plot(y_val, axes):\n",
    "    axes.axhline(y=y_val, color=\"grey\", label=\"Optimal solution\", alpha=0.5)\n",
    "    \n",
    "def add_evo_plot(path: str, yaxis_label: str, axes, column: str = \"num_of_satisfied_clauses\"):\n",
    "    evo_table = get_evo_table(path)\n",
    "    \n",
    "    data = evo_table.sort_values(by=\"step\").set_index([\"step\"]).loc[:, column]\n",
    "    \n",
    "    ax = axes.plot(data, label=f'{yaxis_label}', alpha=0.8)\n",
    "    return evo_table\n",
    "\n",
    "def create_num_of_valid_table(table, column_name: str, table_name: str = \"unknown\"):\n",
    "    t = table.query(\"is_valid == True\").copy()\n",
    "    \n",
    "    t = t.groupby([column_name, \"algorithm_name\"])[\"is_valid\"].count().reset_index()\n",
    "    entries_count_table = table.groupby([column_name, \"algorithm_name\"])[\"is_valid\"].count().reset_index()\n",
    "    t[\"% valid\"] = t[\"is_valid\"]/entries_count_table[\"is_valid\"]\n",
    "    \n",
    "    t = t.drop(columns=[\"is_valid\"])\n",
    "    t = t.round(6)\n",
    "    \n",
    "    # Construct, unstack\n",
    "    #avg_error = avg_error.set_index([\"algorithm_name\", column_name]).unstack(\"algorithm_name\")\n",
    "    #avg_error = error_max.join(error_avg).round(6)\n",
    "    #avg_error.columns = [\"max_relative_error\", \"avg_relative_error\"]\n",
    "    t.name = f\"Avg & max relative error per {column_name}\"\n",
    "    t = t.set_index([\"algorithm_name\", column_name]).unstack(\"algorithm_name\")\n",
    "    \n",
    "    \n",
    "    t.round(3).to_excel(f\"excel/{table_name}_num_of_valid.xlsx\", sheet_name=table_name)\n",
    "    \n",
    "    return t\n",
    "\n",
    "def create_avg_time_table(table, name: str, column_name: str = \"item_count\"):\n",
    "    # Create a table of average times according to algorithm and item_count columns\n",
    "    avg_times = table.groupby([\"algorithm_name\", column_name])['elapsed_time'] \\\n",
    "        .mean().reset_index()\n",
    "    #avg_times = avg_times.round(2)\n",
    "    \n",
    "    avg_configs = table.groupby([\"algorithm_name\", column_name])['elapsed_configs']\\\n",
    "        .mean().reset_index()\n",
    "    \n",
    "    avg_times = avg_times.merge(avg_configs, on=[\"algorithm_name\", column_name])\n",
    "\n",
    "    # Move all values of algorithm column into separate columns\n",
    "    #avg_times = avg_times.unstack(\"algorithm_name\")\n",
    "    #avg_times.columns = avg_times.columns.droplevel()\n",
    "    avg_times.name = f\"Avg #configs per {column_name}\"\n",
    "    avg_times.sort_values(by=column_name, inplace=True)\n",
    "    #avg_times.fillna(\"-\", inplace=True)\n",
    "    \n",
    "    avg_times = avg_times.set_index([\"algorithm_name\", column_name]).unstack(\"algorithm_name\")\n",
    "\n",
    "    # Save the dataframe to csv\n",
    "    avg_times.to_excel(f'excel/{name}_avg_times.xlsx', sheet_name=name)\n",
    "    \n",
    "    return avg_times\n",
    "\n",
    "def create_avg_error_table_by_best_value(table, column_name: str, table_name: str = \"unknown\"):\n",
    "    t = table.query(\"has_best_value == True\").copy()\n",
    "    t = t.fillna(0)\n",
    "    \n",
    "    error_group = t.groupby([column_name, \"algorithm_name\"])[\"relative_mistake_weights\"]\n",
    "\n",
    "    error_max = error_group.max().reset_index() \\\n",
    "        .rename(columns={'relative_mistake_weights':'max_relative_error'})\n",
    "    error_avg = error_group.mean().reset_index() \\\n",
    "        .rename(columns={'relative_mistake_weights':'avg_relative_error'})\n",
    "    \n",
    "    # Construct, unstack\n",
    "    avg_error = pandas.merge(error_max, error_avg, on=[column_name, \"algorithm_name\"])\n",
    "    #avg_error = avg_error.set_index([\"algorithm_name\", column_name]).unstack(\"algorithm_name\")\n",
    "    #avg_error = error_max.join(error_avg).round(6)\n",
    "    #avg_error.columns = [\"max_relative_error\", \"avg_relative_error\"]\n",
    "    avg_error.name = f\"Avg & max relative error per {column_name}\"\n",
    "    avg_error = avg_error.set_index([\"algorithm_name\", column_name]).unstack(\"algorithm_name\")\n",
    "    \n",
    "    \n",
    "    avg_error.to_excel(f\"excel/{table_name}_avg_error_bestvalue.xlsx\", sheet_name=table_name)\n",
    "    \n",
    "    return avg_error\n",
    "\n",
    "def create_avg_error_table_by_clauses(table, column_name: str, table_name: str = \"unknown\"):\n",
    "    t = table.query(\"has_best_value == True\").copy()\n",
    "    t = t.fillna(0)\n",
    "    \n",
    "    error_group = t.groupby([column_name, \"algorithm_name\"])[\"relative_mistake_clauses\"]\n",
    "\n",
    "    error_max = error_group.max().reset_index() \\\n",
    "        .rename(columns={'relative_mistake_clauses':'max_relative_error'})\n",
    "    error_avg = error_group.mean().reset_index() \\\n",
    "        .rename(columns={'relative_mistake_clauses':'avg_relative_error'})\n",
    "    \n",
    "    # Construct, unstack\n",
    "    avg_error = pandas.merge(error_max, error_avg, on=[column_name, \"algorithm_name\"])\n",
    "    #avg_error = avg_error.set_index([\"algorithm_name\", column_name]).unstack(\"algorithm_name\")\n",
    "    #avg_error = error_max.join(error_avg).round(6)\n",
    "    #avg_error.columns = [\"max_relative_error\", \"avg_relative_error\"]\n",
    "    avg_error.name = f\"Avg & max relative error per {column_name}\"\n",
    "    avg_error = avg_error.set_index([\"algorithm_name\", column_name]).unstack(\"algorithm_name\")\n",
    "    \n",
    "    \n",
    "    #avg_error.round(6).to_excel(f\"excel/{table_name}_avg_error_clauses.xlsx\", sheet_name=table_name)\n",
    "    \n",
    "    return avg_error\n",
    "\n",
    "def get_full_table_for_dataset(instance_path: str, sol_path: str, instance_cols, sol_cols):\n",
    "    output_table = None\n",
    "    \n",
    "    # Get all solutions from all files\n",
    "    output_table = pandas.read_csv(instance_path, index_col=None, delimiter=\" \", header=None)\\\n",
    "        .iloc[:, [0, 1,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]]\n",
    "    output_table.columns = instance_cols\n",
    "\n",
    "    # Add data from solution file\n",
    "    sols_table = pandas.read_csv(sol_path, index_col=None, delimiter=\" \", header=None)\\\n",
    "        .iloc[:, [0, 1]]\n",
    "    sols_table.columns = sol_cols\n",
    "    sols_table.drop_duplicates(subset=\"output_filename\", inplace=True)\n",
    "        \n",
    "    output_table = pandas.merge(sols_table, output_table, on=[\"output_filename\"], how=\"outer\")\n",
    "    output_table = output_table.astype({'found_value': 'int64'})\n",
    "    output_table[\"relative_mistake_weights\"] = numpy.abs(output_table[\"best_value\"] - output_table[\"found_value\"])/output_table[\"best_value\"]\n",
    "\n",
    "    output_table[\"relative_mistake_clauses\"] = (output_table[\"num_of_clauses\"] - output_table[\"num_of_satisfied_clauses\"])/output_table[\"num_of_satisfied_clauses\"]\n",
    "    output_table[\"has_best_value\"] = ~numpy.isnan(output_table[\"best_value\"])\n",
    "    \n",
    "    output_table = output_table.fillna(0.0).astype({'best_value': 'int64'})\n",
    "    \n",
    "    return output_table\n",
    "\n",
    "def get_all_tables_of_results(base: str):\n",
    "    cols = get_cols_list(\"column_description.dat\")\n",
    "    cols.remove(\"vars_output\")\n",
    "    dfs = list()\n",
    "    \n",
    "    datasets = [\n",
    "        \"wuf-A/wuf20-88-A\",\n",
    "        \"wuf-A/wuf20-91-A\",\n",
    "        \n",
    "        \"wuf-M/wuf20-78-M\",\n",
    "        \"wuf-M/wuf50-201-M\",\n",
    "        \n",
    "        \"wuf-N/wuf20-78-N\",\n",
    "        \"wuf-N/wuf50-201-N\",\n",
    "        \n",
    "        \"wuf-Q/wuf20-78-Q\",\n",
    "        \"wuf-Q/wuf50-201-Q\",\n",
    "        \n",
    "        \"wuf-R/wuf20-78-R\",\n",
    "        \"wuf-R/wuf50-201-R\"\n",
    "    ]\n",
    "    for algorithm in [\"SA_SAT_V1\", \"SA_SAT_V2\", \"SA_SAT_V3\"]:\n",
    "        \n",
    "        for dataset in datasets:\n",
    "            d = get_full_table_for_dataset(f'{base}/{dataset}_{algorithm}.dat', f'{sol_path}/{dataset}-opt.dat', cols, sol_cols)\n",
    "            dfs.append(d)\n",
    "    \n",
    "    return pandas.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_simple = get_all_tables_of_results(\"tester_results_V1_Simple\")\n",
    "v2_moreCooling = get_all_tables_of_results(\"tester_results_V2_MoreCooling\")\n",
    "v3_higherTemp = get_all_tables_of_results(\"tester_results_V3_HigherTemp\")\n",
    "v4_moreCycles = get_all_tables_of_results(\"tester_results_V4_MoreCycles\")\n",
    "v5_lowerTemp = get_all_tables_of_results(\"tester_results_V5_LowerTemp\")\n",
    "v6_higherTemp = get_all_tables_of_results(\"tester_results_V6_HigherTemp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(100*v1_simple.query(\"algorithm_name == 'SA_SAT_V1'\").query(\"is_valid == False\")[\"algorithm_name\"].count() / v1_simple.query(\"algorithm_name == 'SA_SAT_V1'\")[\"algorithm_name\"].count())\n",
    "\n",
    "v1_simple.query(\"algorithm_name == 'SA_SAT_V3'\").query(\"relative_mistake_weights > 0.6\")[\"algorithm_name\"].count()\n",
    "\n",
    "v1_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table = v1_simple.append(v3_higherTemp).append(v6_higherTemp)\n",
    "\n",
    "error_init_temp = create_avg_error_table_by_best_value(full_table, \"init_temperature\")\n",
    "save_plot(error_init_temp, \"Avg error - init temperatures\", \"avg_relative_error\", \"init_temp_avg_error\")\n",
    "\n",
    "\n",
    "time_init_temp = create_avg_time_table(full_table, \"init_temperature\", \"init_temperature\")\n",
    "save_plot(time_init_temp, \"Avg speed - init temperatures\", \"elapsed_time\", \"init_temp_time_ms\", \"Time[ms]\")\n",
    "\n",
    "create_num_of_valid_table(full_table, \"init_temperature\", \"init_temperature\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table = v1_simple.append(v4_moreCycles)\n",
    "\n",
    "error_cycles = create_avg_error_table_by_best_value(full_table, \"cycles\")\n",
    "save_plot(error_cycles, \"Avg error - cycles\", \"avg_relative_error\", \"cycles_avg_error\")\n",
    "\n",
    "\n",
    "time_cycles = create_avg_time_table(full_table, \"cycles\", \"cycles\")\n",
    "save_plot(time_cycles, \"Avg speed - cycles\", \"elapsed_time\", \"cycles_time_ms\", \"Time[ms]\")\n",
    "\n",
    "\n",
    "create_num_of_valid_table(full_table, \"cycles\", \"cycles\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cooling coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table = v1_simple.append(v2_moreCooling)\n",
    "\n",
    "error_cooling = create_avg_error_table_by_best_value(full_table, \"cooling\")\n",
    "save_plot(error_cooling, \"Avg error - cooling coefficients\", \"avg_relative_error\", \"cooling_avg_error\")\n",
    "\n",
    "time_cooling = create_avg_time_table(full_table, \"cooling\", \"cooling\")\n",
    "save_plot(time_cooling, \"Avg speed - cooling coefficients\", \"elapsed_time\", \"cooling_time_ms\", \"Time[ms]\")\n",
    "\n",
    "create_num_of_valid_table(full_table, \"cooling\", \"cooling\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table = v1_simple.append(v5_lowerTemp)\n",
    "\n",
    "error_min_temp = create_avg_error_table_by_best_value(full_table, \"min_temperature\")\n",
    "save_plot(error_min_temp, \"Avg error - minimum temperature\", \"avg_relative_error\", \"min_temp_avg_error\")\n",
    "\n",
    "time_min_temp = create_avg_time_table(full_table, \"min_temperature\", \"min_temperature\")\n",
    "save_plot(time_min_temp, \"Avg speed - minimum temperature\", \"elapsed_time\", \"min_temp_time_ms\", \"Time[ms]\")\n",
    "\n",
    "create_num_of_valid_table(full_table, \"min_temperature\", \"min_temperature\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evo files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_clauses = 201\n",
    "best_weight = 13570\n",
    "\n",
    "fig, axes = init_evo_plot(\"Base evo files for different algorithm versions\")\n",
    "\n",
    "add_evo_plot(f\"{evo_path}/simple/wuf50-0987_SA_SAT_V1_sol.evo\", \"V1\", axes)\n",
    "add_evo_plot(f\"{evo_path}/simple/wuf50-0987_SA_SAT_V2_sol.evo\", \"V2\", axes)\n",
    "add_evo_plot(f\"{evo_path}/simple/wuf50-0987_SA_SAT_V3_sol.evo\", \"V3\", axes)\n",
    "add_optimal_sol_plot(num_of_clauses, axes)\n",
    "axes.legend()\n",
    "fig.savefig(f\"excel/algorithm_comparison_evo_clauses.pdf\")\n",
    "\n",
    "fig, axes = init_evo_plot(\"Base evo files for different algorithm versions\", ylabel=\"Sum weight\")\n",
    "\n",
    "add_evo_plot(f\"{evo_path}/simple/wuf50-0987_SA_SAT_V1_sol.evo\", \"V1\", axes, \"weight\")\n",
    "add_evo_plot(f\"{evo_path}/simple/wuf50-0987_SA_SAT_V2_sol.evo\", \"V2\", axes, \"weight\")\n",
    "add_evo_plot(f\"{evo_path}/simple/wuf50-0987_SA_SAT_V3_sol.evo\", \"V3\", axes, \"weight\")\n",
    "add_optimal_sol_plot(best_weight, axes)\n",
    "axes.legend()\n",
    "fig.savefig(f\"excel/algorithm_comparison_evo_weight.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = init_evo_plot(\"Initial temperature comparison for V3\", ylabel=\"Sum weight\")\n",
    "\n",
    "add_evo_plot(f\"{evo_path}/simple/wuf50-0987_SA_SAT_V3_sol.evo\", \"InitTemp_1000\", axes, \"weight\")\n",
    "add_evo_plot(f\"{evo_path}/init_temp/5000/wuf50-0987_SA_SAT_V3_sol.evo\", \"InitTemp_5000\", axes, \"weight\")\n",
    "add_evo_plot(f\"{evo_path}/init_temp/10000/wuf50-0987_SA_SAT_V3_sol.evo\", \"InitTemp_10000\", axes, \"weight\")\n",
    "add_optimal_sol_plot(best_weight, axes)\n",
    "axes.legend()\n",
    "fig.savefig(f\"excel/init_temp_comparison_evo_weight.pdf\")\n",
    "\n",
    "fig, axes = init_evo_plot(\"Initial temperature comparison for V3\")\n",
    "\n",
    "add_evo_plot(f\"{evo_path}/simple/wuf50-0987_SA_SAT_V3_sol.evo\", \"InitTemp_1000\", axes)\n",
    "add_evo_plot(f\"{evo_path}/init_temp/5000/wuf50-0987_SA_SAT_V3_sol.evo\", \"InitTemp_5000\", axes)\n",
    "add_evo_plot(f\"{evo_path}/init_temp/10000/wuf50-0987_SA_SAT_V3_sol.evo\", \"InitTemp_10000\", axes)\n",
    "add_optimal_sol_plot(num_of_clauses, axes)\n",
    "axes.legend()\n",
    "fig.savefig(f\"excel/init_temp_comparison_evo_clauses.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
