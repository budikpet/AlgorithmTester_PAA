{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for renaming and moving solution files from tester_results to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = \"/Users/petr/Documents/Projects/Python/AlgorithmTester/analysis/tester_results/DataAnalysis\"\n",
    "dest_path = \"/Users/petr/Documents/Projects/Python/AlgorithmTester/data/DataAnalysis\"\n",
    "\n",
    "dry_run: bool = True\n",
    "\n",
    "for root, dirs, files in os.walk(source_path):\n",
    "    print(f\"{root}\")\n",
    "    dir_name: str = root.split(\"/\")[-1]\n",
    "    for filename in files:\n",
    "        if \"column\" in filename or \"DPWeight\" not in filename:\n",
    "            continue\n",
    "                   \n",
    "        split = filename.split(\"_\")\n",
    "        split = [split[0], split[1], split[4]]\n",
    "        new_name: str = '_'.join(split)\n",
    "            \n",
    "        print(f'{dest_path}/{dir_name}/{split[1]}/{new_name}')\n",
    "            \n",
    "        if not dry_run:\n",
    "            os.rename(f'{root}/{filename}', f'{dest_path}/{dir_name}/{split[1]}/{new_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for aggregating SAT solutions from multiple files to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_files(results_path: str, output_file_path: str, algorithm_name: str):\n",
    "    output_file_path = output_file_path.replace(\".dat\", f'_{algorithm_name}.dat')\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "        for root, _, files in os.walk(results_path):\n",
    "            for file in files:\n",
    "                if \"column\" in file or algorithm_name not in file:\n",
    "                    continue\n",
    "                res_file = open(f'{root}/{file}')\n",
    "                output_file.write(res_file.read())\n",
    "                res_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"tester_results_V1_Simple\",\n",
    "    \"tester_results_V2_MoreCooling\",\n",
    "    \"tester_results_V3_HigherTemp\",\n",
    "    \"tester_results_V4_MoreCycles\",\n",
    "    \"tester_results_V5_LowerTemp\",\n",
    "    \"tester_results_V6_HigherTemp\"\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "    results_base = f\"/Users/petr/Documents/Projects/Python/AlgorithmTester/analysis/{dataset}\"\n",
    "    \n",
    "    all_results = {\n",
    "        f'{results_base}/wuf-A/wuf20-88-A': f'{results_base}/wuf-A/wuf20-88-A.dat',\n",
    "        f'{results_base}/wuf-A/wuf20-91-A': f'{results_base}/wuf-A/wuf20-91-A.dat',\n",
    "\n",
    "        f'{results_base}/wuf-M/wuf20-78-M': f'{results_base}/wuf-M/wuf20-78-M.dat',\n",
    "        f'{results_base}/wuf-M/wuf50-201-M': f'{results_base}/wuf-M/wuf50-201-M.dat',\n",
    "\n",
    "        f'{results_base}/wuf-N/wuf20-78-N': f'{results_base}/wuf-N/wuf20-78-N.dat',\n",
    "        f'{results_base}/wuf-N/wuf50-201-N': f'{results_base}/wuf-N/wuf50-201-N.dat',\n",
    "\n",
    "        f'{results_base}/wuf-Q/wuf20-78-Q': f'{results_base}/wuf-Q/wuf20-78-Q.dat',\n",
    "        f'{results_base}/wuf-Q/wuf50-201-Q': f'{results_base}/wuf-Q/wuf50-201-Q.dat',\n",
    "\n",
    "        f'{results_base}/wuf-R/wuf20-78-R': f'{results_base}/wuf-R/wuf20-78-R.dat',\n",
    "        f'{results_base}/wuf-R/wuf50-201-R': f'{results_base}/wuf-R/wuf50-201-R.dat',\n",
    "    }\n",
    "\n",
    "    for results_path, output_file_path in all_results.items():\n",
    "        for algorithm_name in [\"SA_SAT_V1\", \"SA_SAT_V2\", \"SA_SAT_V3\"]:\n",
    "            aggregate_files(results_path, output_file_path, algorithm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read lines of file in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import move\n",
    "\n",
    "path = \"/Users/petr/Documents/Projects/Python/AlgorithmTester/analysis/tester_results_V2_moreAccurate\"\n",
    "\n",
    "def remove(path):\n",
    "    print(\"running\")\n",
    "    with open(f\"{path}_N\", \"w\") as new_file:\n",
    "        with open(path) as res_file:\n",
    "            line = res_file.readline()\n",
    "            while line is not None and line != '':\n",
    "                split = line.split()\n",
    "                if len(split) <= 32:\n",
    "                    new_file.write(line)\n",
    "                #print(line)\n",
    "                line = res_file.readline()\n",
    "    \n",
    "    print(\"renaming\")\n",
    "    move(f\"{path}_N\", path)\n",
    "                \n",
    "remove(f'{path}/wuf-N/wuf20-78-N.dat')\n",
    "remove(f'{path}/wuf-Q/wuf20-78-Q.dat')\n",
    "remove(f'{path}/wuf-M/wuf20-78-M.dat')\n",
    "remove(f'{path}/wuf-R/wuf20-78-R.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import move\n",
    "\n",
    "path = \"/Users/petr/Documents/Projects/Python/AlgorithmTester/data\"\n",
    "\n",
    "def remove(path):\n",
    "    print(\"running\")\n",
    "    with open(f\"{path}_N\", \"w\") as new_file:\n",
    "        with open(path) as res_file:\n",
    "            line = res_file.readline()\n",
    "            while line is not None and line != '':\n",
    "                split = line.split()\n",
    "                if len(split) <= 32:\n",
    "                    new_file.write(line)\n",
    "                #print(line)\n",
    "                line = res_file.readline()\n",
    "    \n",
    "    print(\"renaming\")\n",
    "    move(f\"{path}_N\", path)\n",
    "                \n",
    "remove(f'{path}/wuf-N/wuf20-78-N-opt.dat')\n",
    "remove(f'{path}/wuf-Q/wuf20-78-Q-opt.dat')\n",
    "remove(f'{path}/wuf-M/wuf20-78-M-opt.dat')\n",
    "remove(f'{path}/wuf-R/wuf20-78-R-opt.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "filepath: str = '../data/UnitTest/NK10_inst.dat'\n",
    "\n",
    "# How many lines are read at once    \n",
    "batch_size: int = 50\n",
    "    \n",
    "with open(filepath, \"r\") as file:\n",
    "    batch: List[str] = [x.strip() for x in islice(file, batch_size)]\n",
    "    while len(batch) > 0:\n",
    "        for instance in batch:\n",
    "            print(instance)\n",
    "        \n",
    "        batch = [x.strip() for x in islice(file, batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package_parsers.knapsack_parser import KnapsackParser\n",
    "\n",
    "def get_batch(parser, file, batch_size):\n",
    "    batch = list()\n",
    "    cntr: int = 0\n",
    "    parsed_data = parser.get_next_instance(file)\n",
    "    \n",
    "    while (parsed_data is not None) and cntr < batch_size:\n",
    "        batch.append(parsed_data)\n",
    "\n",
    "        cntr += 1\n",
    "        parsed_data = parser.get_next_instance(file)\n",
    "        \n",
    "    return batch\n",
    "\n",
    "parser: KnapsackParser = KnapsackParser()\n",
    "filepath: str = '../data/UnitTest/NK10_inst.dat'\n",
    "\n",
    "# How many lines are read at once    \n",
    "batch_size: int = 5\n",
    "    \n",
    "with open(filepath, \"r\") as file:\n",
    "    batch = get_batch(parser, file, batch_size)\n",
    "    \n",
    "    while len(batch) > 0:\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yield test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance(cnt: int):\n",
    "    for i in range(cnt):\n",
    "        yield i\n",
    "    \n",
    "algorithms = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "for alg in algorithms:\n",
    "    it = get_instance(5)\n",
    "    \n",
    "    for res in it:\n",
    "        print(f'{alg}:{res}')\n",
    "        \n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy ConcurrencyStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "# Common functions\n",
    "\n",
    "def get_res(algorithm: str, instance: Dict[str, object]):\n",
    "    print(f\"Getting res for {instance} using {algorithm}.\")\n",
    "    time.sleep(1)\n",
    "    return f'Ran {algorithm} for {instance}.'\n",
    "\n",
    "def get_instance(file: str):\n",
    "    output = dict()\n",
    "    \n",
    "    for i in range(2):\n",
    "        output = {\"input\": file, \"instance\": i}\n",
    "        yield output\n",
    "    \n",
    "def run_tester_for_file(filename: str):\n",
    "    for algorithm in [\"A\", \"B\"]:\n",
    "        it = get_instance(f'{filename}_opened')\n",
    "        \n",
    "        for instance in it:\n",
    "            res = get_res(algorithm, instance)\n",
    "            print(f\"Writing (\\'{res}\\') to results file for input file {filename}.\")\n",
    "\n",
    "            \n",
    "# Runners\n",
    "filenames = [f'File{i}' for i in range(2)]\n",
    "\n",
    "\n",
    "class BaseRunner:\n",
    "    \n",
    "    def start(self):\n",
    "        for filename in filenames:\n",
    "            run_tester_for_file(filename)\n",
    "\n",
    "class ConcurrentFilesRunner:\n",
    "    \n",
    "    def start(self):\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            batch = filenames\n",
    "            futures = [executor.submit(run_tester_for_file, filename) for filename in batch]\n",
    "            \n",
    "class ConcurrentInstancesRunner:\n",
    "    \n",
    "    def start(self):\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            \n",
    "            for filename in filenames:\n",
    "                for algorithm in [\"A\", \"B\"]:\n",
    "                    batch = [instance for instance in get_instance(f'{filename}_opened')]\n",
    "                    futures = [executor.submit(get_res, instance, algorithm) for instance in batch]\n",
    "\n",
    "                    for future in concurrent.futures.as_completed(futures):\n",
    "                        res = future.result()\n",
    "                        print(f\"Writing (\\'{res}\\') to results file for input file {filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test BaseRunner\n",
    "start = time.perf_counter()\n",
    "\n",
    "simple_runner = BaseRunner()\n",
    "simple_runner.start()\n",
    "\n",
    "finish = time.perf_counter()\n",
    "print(f'Finished task in {round(finish - start, 2)} second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ConcurrentFilesRunner\n",
    "start = time.perf_counter()\n",
    "\n",
    "simple_runner = ConcurrentFilesRunner()\n",
    "simple_runner.start()\n",
    "\n",
    "finish = time.perf_counter()\n",
    "print(f'Finished task in {round(finish - start, 2)} second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ConcurrentInstancesRunner\n",
    "start = time.perf_counter()\n",
    "\n",
    "simple_runner = ConcurrentInstancesRunner()\n",
    "simple_runner.start()\n",
    "\n",
    "finish = time.perf_counter()\n",
    "print(f'Finished task in {round(finish - start, 2)} second(s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = \"/Users/petr/Documents/Projects/Python/AlgorithmTester/analysis/tester_results\"\n",
    "tmp_filepath = \"/Users/petr/Documents/Projects/Python/AlgorithmTester/analysis/tester_results/help.tmp\"\n",
    "\n",
    "for root, _, files in os.walk(source_path):\n",
    "    for file in files:\n",
    "        if \".mwcnf\" not in file:\n",
    "            continue\n",
    "        input_filename = f'{root}/{file}'\n",
    "        \n",
    "        with open(input_filename, \"r\") as input_file:\n",
    "            with open(f'{tmp_filepath}', \"w\") as tmp_file:\n",
    "                tmp_file.write(input_file.readline().replace(\".cnf\", \"\"))\n",
    "           \n",
    "        shutil.move(tmp_filepath, input_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
